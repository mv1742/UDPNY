{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary6typ = 'pct_ch_percol00_16_binary'\n",
    "model_name = '1_FQ_Binaries_pct_ch_percol00_16_binary_binary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Foursquare Data\n",
    "# NYU - CUSP UDP Capstone\n",
    "# Foursquare + NYC Merge by CT \n",
    "## Brief\n",
    "This notebook \n",
    "1. Part I. Data Processing\n",
    "\n",
    "    - import Foursquare data\n",
    "    - imports the Census Tract shapefile\n",
    "    - import Typologies\n",
    "    - merges topologies\n",
    "    - Spatail join by Census Tract\n",
    "    - merges topologies\n",
    "    - map topologies\n",
    "    - map Businesses\n",
    "1. Part II. Data Processing\n",
    "    - Performs a classifcation task on Typologies\n",
    "###  You can refer to https://github.com/mv1742/updny_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/ADS/lib/python3.5/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['Polygon', 'linalg']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import shapely\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "#make sure plots are embedded into the notebook\n",
    "%matplotlib inline\n",
    "#import statsmodels.formula.api as smf\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from sklearn.metrics import silhouette_score\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "from scipy import linalg\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  # for hierarchical clustering\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "from scipy import linalg\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  # for hierarchical clustering\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import geopandas as gpd\n",
    "import pylab as pl\n",
    "import io\n",
    "import pylab as pl\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "from geopandas.tools import sjoin\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    hasWidgets = True\n",
    "except ImportError:\n",
    "    hasWidgets = False\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, classification_report\n",
    "import matplotlib.pylab\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYU - CUSP UDP Capstone\n",
    "# Foursquare + NYC Merge by CT \n",
    "## Brief\n",
    "This notebook \n",
    "- import Foursquare data\n",
    "- imports the Census Tract shapefile\n",
    "- import Typologies\n",
    "- merges topologies\n",
    "- Spatail join by Census Tract\n",
    "- merges topologies\n",
    "- map topologies\n",
    "- map Businesses\n",
    "- outputs a .csv of the results\n",
    "- You can refer to https://github.com/mv1742/updny_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare Data\n",
    "- import Foursquare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpd.read_file('NYU_March2018_subset30.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['id',\n",
       "  'Place Name',\n",
       "  'Rating',\n",
       "  'Checkins',\n",
       "  'Users',\n",
       "  'Visits',\n",
       "  'Pricing',\n",
       "  'Type',\n",
       "  'Category',\n",
       "  'Class',\n",
       "  'geometry'],\n",
       " (106287, 11))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(data.columns)), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Place Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Checkins</th>\n",
       "      <th>Users</th>\n",
       "      <th>Visits</th>\n",
       "      <th>Pricing</th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50ad0afce4b0b4a7430e2268</td>\n",
       "      <td>Terry's Wine Shop</td>\n",
       "      <td>8.8</td>\n",
       "      <td>294</td>\n",
       "      <td>217</td>\n",
       "      <td>337</td>\n",
       "      <td>None</td>\n",
       "      <td>Wine Shop</td>\n",
       "      <td>Consumption</td>\n",
       "      <td>Optional</td>\n",
       "      <td>POINT (-74.00034036700906 40.73518392010902)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id         Place Name  Rating  Checkins  Users  \\\n",
       "0  50ad0afce4b0b4a7430e2268  Terry's Wine Shop     8.8       294    217   \n",
       "\n",
       "   Visits Pricing       Type     Category     Class  \\\n",
       "0     337    None  Wine Shop  Consumption  Optional   \n",
       "\n",
       "                                       geometry  \n",
       "0  POINT (-74.00034036700906 40.73518392010902)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type', 'Category', 'Class']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)[-4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106287, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(106287, 716)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dummies = data[list(data.columns)[-4:-1]]\n",
    "print(X_dummies.shape)\n",
    "X_dummies = pd.get_dummies(X_dummies)\n",
    "Fq_dummies = pd.concat([data, X_dummies], axis=1, join='inner')  \n",
    "Fq_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census Tract shapefile\n",
    "- imports the Census Tract shapefile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory for shapefiles and set the environmental variable to it\n",
    "\n",
    "#masterdata = os.getenv(\"Master\")\n",
    "#if masterdata is None:\n",
    "#    os.environ[\"Master\"] = \"{}/Capstone/udpny_2\".format(os.getenv(\"HOME\"))\n",
    "#    masterdata = os.getenv(\"Master\")\n",
    "#    print(\"Warning: Master environmental variable not found and set by code, please review!\")\n",
    "#print(\"Master: {}\".format(masterdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory for shapefiles and set the environmental variable to it\n",
    "\n",
    "# masterdata = os.getenv(\"Master\")\n",
    "# if masterdata is None:\n",
    "#     os.environ[\"Master\"] = \"{}/Capstone/udpny_2\".format(os.getenv(\"HOME\"))\n",
    "#     masterdata = os.getenv(\"Master\")\n",
    "#     print(\"Warning: Master environmental variable not found and set by code, please review!\")\n",
    "# print(\"Master: {}\".format(masterdata))\n",
    "# def getGeoDataFrameFromShpFileZipUrl(url):\n",
    "#     '''\n",
    "#     This function downloads the zip file, unzips it into the dorectory \n",
    "#     pointed to by PUIdata environment variable. Then it \n",
    "#     reads it into a gepandas dataframe\n",
    "#     '''\n",
    "    \n",
    "#     folderName = 'shape'+ \\\n",
    "#         str(len(os.listdir(os.getenv('TaxiData')))+1)\n",
    "#     os.makedirs(os.getenv('Master') + '/' + folderName)\n",
    "#     urlretrieve(url, \"region.zip\")\n",
    "#     os.system('unzip -d $Master'+'/'+folderName+' region.zip')\n",
    "#     filenames = [f for f in os.listdir(os.getenv('Master') + '/' + folderName) if f.endswith('.shp') ]\n",
    "#     shapeFile = filenames[0]\n",
    "#     shapeFilePath = os.getenv('Master') + '/' + folderName + '/' + shapeFile\n",
    "#     return gpd.GeoDataFrame.from_file(shapeFilePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://planninglabs.carto.com/api/v2/sql?filename=region&q=SELECT%20%2A%20FROM%20region_censustract_v0&format=SHP'\n",
    "# NYCzip = getGeoDataFrameFromShpFileZipUrl(url)\n",
    "NYCzip=gpd.read_file('Censustracts/region.shp')\n",
    "NYCzip.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCzip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCzip.rename(columns={\"geoid\": \"GEOID\"},inplace=True)\n",
    "NYCzip.GEOID = NYCzip.GEOID.astype(int)\n",
    "cols = ['GEOID','geometry']\n",
    "NYCzip = NYCzip.loc[:,cols]\n",
    "#NYCzipgdp.plot(column='GEOID',legend = True)\n",
    "NYCzip.shape\n",
    "NYCzip.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(15, 15))\n",
    "NYCzip.plot(column='GEOID',legend = True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typologies\n",
    "- import raw Typology file with Census data 'NY_final_data_for_typologies_1.19.19.csv'\n",
    "- merges Typologies with the new Binary typologies\n",
    "- map topologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Typologiespd=pd.read_csv('NY_final_data_for_typologies_1.19.19.csv')\n",
    "Typologiesgdp = gpd.GeoDataFrame(Typologiespd)\n",
    "len(Typologiesgdp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Typologiesgdp.rename(columns={'geoid': \"GEOID\"},inplace=True)\n",
    "Typologiesgdp.tail()\n",
    "cols_typ = ['GEOID','Type_1.19']\n",
    "print(type(Typologiesgdp.iloc[:,0][0]))\n",
    "#Typologies.rename(columns={'\\ufeffgeoid': \"GEOID\"},inplace=True)\n",
    "#Typologiesgdp.geoid = Typologies.iloc[:,0]\n",
    "Typologiesgdp = Typologiesgdp.loc[:,cols_typ]\n",
    "Typologiesgdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binaries=pd.read_csv('./Data/NEW_6_BINARIES_ALL.csv')\n",
    "len(Binaries.columns), Binaries.shape\n",
    "Binaries.drop(columns = 'Unnamed: 0', inplace=True)\n",
    "Binaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_typs = ['pct_ch_hinc00_16_binary',\n",
    "            'pct_ch_medhval00_16_binary','pct_ch_medrent00_16_binary','Ongoing_adv_gent',\n",
    "            'gent00_16','gent90_00','Supergent16']\n",
    "for i, column in enumerate(bin_typs):\n",
    "    plt.figure(1)\n",
    "    plt.subplot(4,4,i+1)\n",
    "    Binaries[column].value_counts().plot(kind='bar', figsize = (15,15), title=column)\n",
    "    Binaries[column].value_counts()/Binaries[column].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Typologiesgdp = Typologiesgdp.merge(Binaries, on= 'GEOID')\n",
    "Typologiesgdp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Typologiesgdp.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = NYCzip.merge(Typologiesgdp,on='GEOID')\n",
    "merged.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(merged),merged.shape)\n",
    "mergedgpd = gpd.GeoDataFrame(merged)\n",
    "mergedgpd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD FOURSQUARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighbours\n",
    "X_foursquare_neighbours = pd.read_csv('Improve_Features/X_foursquare-neighbours.csv')\n",
    "print(X_foursquare_neighbours.shape,X_foursquare_neighbours.columns)\n",
    "X_foursquare_neighbours.drop(['Unnamed: 0'],axis =1, inplace=True)\n",
    "cols_neighbours = []\n",
    "for column in X_foursquare_neighbours.columns:\n",
    "    if '_sum10' in column:\n",
    "        cols_neighbours.append(column)\n",
    "cols_neighbours = cols_neighbours + ['GEOID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances\n",
    "X_foursquare_high = pd.read_csv('Improve_Features/X_foursquare-distances_high.csv')\n",
    "\n",
    "print(X_foursquare_high.shape,X_foursquare_high.columns)\n",
    "cols_high = []\n",
    "for column in X_foursquare_high.columns:\n",
    "    if 'distance' in column:\n",
    "        cols_high.append(column)\n",
    "cols_high = cols_high + ['GEOID']\n",
    "cols_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare_low = pd.read_csv('Improve_Features/X_foursquare-distances_low.csv')\n",
    "print(X_foursquare_low.shape,X_foursquare_low.columns)\n",
    "cols_low = []\n",
    "for column in X_foursquare_low.columns:\n",
    "    if 'distance' in column:\n",
    "        cols_low.append(column)\n",
    "cols_low = cols_low + ['GEOID']\n",
    "cols_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances- numeric \n",
    "X_foursquare_numeric = pd.read_csv('Improve_Features/X_foursquare-distances_numeric.csv')\n",
    "print(X_foursquare_numeric.shape,X_foursquare_numeric.columns)\n",
    "cols_numeric = []\n",
    "for column in X_foursquare_numeric.columns:\n",
    "    if 'distance' in column:\n",
    "        cols_numeric.append(column)\n",
    "cols_numeric = cols_numeric + ['GEOID']\n",
    "cols_numeric\n",
    "# Distances- cats \n",
    "X_foursquare_cats1 = pd.read_csv('Improve_Features/X_foursquare-distances_cats.csv')\n",
    "print(X_foursquare_cats1.shape,X_foursquare_cats1.columns)\n",
    "cols_cats1 = []\n",
    "for column in X_foursquare_cats1.columns:\n",
    "    if 'distance' in column:\n",
    "        cols_cats1.append(column)\n",
    "cols_cats1 = cols_cats1 + ['GEOID']\n",
    "cols_cats1\n",
    "# Distances- class\n",
    "X_foursquare_class = pd.read_csv('Improve_Features/X_foursquare-distances_class.csv')\n",
    "print(X_foursquare_class.shape,X_foursquare_cats1.columns)\n",
    "cols_class = []\n",
    "for column in X_foursquare_class.columns:\n",
    "    if 'distance' in column:\n",
    "        cols_class.append(column)\n",
    "cols_class = cols_class + ['GEOID']\n",
    "cols_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare_neighbours = X_foursquare_neighbours.loc[:,cols_neighbours]\n",
    "X_foursquare_high = X_foursquare_high.loc[:,cols_high]\n",
    "X_foursquare_class = X_foursquare_class.loc[:,cols_class]\n",
    "X_foursquare_cats1 = X_foursquare_cats1.loc[:,cols_cats1]\n",
    "X_foursquare_numeric = X_foursquare_numeric.loc[:,cols_numeric]\n",
    "X_foursquare_low = X_foursquare_low.loc[:,cols_low]\n",
    "# X_foursquare_person = X_foursquare_person.loc[:,cols_person]\n",
    "# X_foursquare_income = X_foursquare_income.loc[:,cols_income]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_foursquare_low.shape, X_foursquare_person.shape\n",
    "print(X_foursquare_high.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare_data_sjoined = pd.read_csv('./data_sjoined_sum_merged.csv')\n",
    "X_foursquare_data_sjoined.drop(columns=['Unnamed: 0','Typologies'],inplace=True)\n",
    "print(X_foursquare_data_sjoined.shape)\n",
    "print(X_foursquare_data_sjoined.shape,X_foursquare_data_sjoined.columns)\n",
    "cols_datasjoined = []\n",
    "for column in X_foursquare_data_sjoined.drop(columns=['geometry']).columns:\n",
    "    if 'Type' not in column:\n",
    "        cols_datasjoined.append(column)\n",
    "cols_datasjoined = cols_datasjoined\n",
    "cols_datasjoined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare_data_sjoined_all = X_foursquare_data_sjoined.drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_foursquare_data_sjoined_pca = X_foursquare_data_sjoined.drop(columns=['geometry']).iloc[:,7:698]\n",
    "\n",
    "X_foursquare_data_sjoined_non_type = X_foursquare_data_sjoined.loc[:,cols_datasjoined]\n",
    "X_foursquare_data_sjoined_non_type.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_foursquare_data_sjoined_other1 = X_foursquare_data_sjoined.drop(columns=['geometry']).iloc[:,698:]\n",
    "# X_foursquare_data_sjoined_other1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_foursquare_data_sjoined_other2 = X_foursquare_data_sjoined.drop(columns=['geometry']).iloc[:,:7]\n",
    "# X_foursquare_data_sjoined_other2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine FQ DATA::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare = X_foursquare_high.merge(X_foursquare_neighbours, on='GEOID')\n",
    "print(X_foursquare.shape)\n",
    "X_foursquare = X_foursquare.merge(X_foursquare_low, on='GEOID')\n",
    "print(X_foursquare.shape)\n",
    "X_foursquare = X_foursquare.merge(X_foursquare_class, on='GEOID')\n",
    "print(X_foursquare.shape)\n",
    "X_foursquare = X_foursquare.merge(X_foursquare_numeric, on='GEOID')\n",
    "print(X_foursquare.shape)\n",
    "X_foursquare = X_foursquare.merge(X_foursquare_cats1, on='GEOID')\n",
    "print(X_foursquare.shape)\n",
    "X_foursquare = X_foursquare.merge(X_foursquare_data_sjoined_all, on='GEOID')\n",
    "print(X_foursquare.shape)\n",
    "print(X_foursquare.shape)\n",
    "print(X_foursquare_low.shape[1],X_foursquare_numeric.shape[1],X_foursquare_cats1.shape[1], X_foursquare_class.shape[1],X_foursquare_high.shape[1])\n",
    "X_foursquare_low.shape,X_foursquare_numeric.shape,X_foursquare_cats1.shape, X_foursquare_class.shape,X_foursquare_high.shape,X_foursquare_neighbours.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD GEOMETRY & TYPOLOGIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_foursquare.shape,X_foursquare.columns)\n",
    "X_foursquare = X_foursquare.merge(mergedgpd, on ='GEOID')\n",
    "print(X_foursquare.shape,X_foursquare.columns[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare.columns[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typologies = ['Type_1.19','pct_ch_percol00_16_binary','pct_ch_hinc00_16_binary',\\\n",
    "           'pct_ch_medhval00_16_binary','pct_ch_medrent00_16_binary','Ongoing_adv_gent',\n",
    "                                        'gent00_16',\n",
    "                                        'gent90_00',\n",
    "                                      'Supergent16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typologies[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_foursquare.shape)\n",
    "X_foursquare.dropna(inplace=True)\n",
    "print(X_foursquare.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_four_temp = gpd.GeoDataFrame(X_foursquare)\n",
    "figure, ax = plt.subplots()\n",
    "X_four_temp.plot(column='GEOID',legend = True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare_beforedrops = X_foursquare.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing Data\n",
    "\n",
    "y = X_foursquare[binary6typ]\n",
    "X_foursquare = X_foursquare.drop(typologies+['GEOID','geometry'],axis =1).copy()\n",
    "print(X_foursquare.shape)\n",
    "X_foursquare.dropna(inplace=True)\n",
    "print(X_foursquare.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "models = ['Raw','Scaled','Minmaxed']\n",
    "Xdata_scaled = preprocessing.scale(X_foursquare)\n",
    "# ydata_scaled = preprocessing.scale(y)\n",
    "\n",
    "Xdata_minmaxed = min_max_scaler.fit_transform(X_foursquare)\n",
    "# ydata_minmaxed = min_max_scaler.fit_transform(y)\n",
    "\n",
    "dictx = {}\n",
    "dictx['Raw'] = X_foursquare\n",
    "dictx['Scaled'] = Xdata_scaled\n",
    "dictx['Minmaxed'] = Xdata_minmaxed\n",
    "                    \n",
    "\n",
    "# x = dictx[model][0]\n",
    "# y = dictx[model][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f1_scores = {}\n",
    "model_recall_scores = {}\n",
    "model_precision_scores = {}\n",
    "imp_dict = {}\n",
    "names_dict ={}\n",
    "model = {}\n",
    "modelslist = ['Logit','DT','RF','SVM'] \n",
    "for m in models:\n",
    "    # X_train[m], X_test[m], y_train[m], y_test[m]\n",
    "    dictx[m]\n",
    "    model[m] = {}\n",
    "    model_f1_scores[m] = {}\n",
    "    model_recall_scores[m] ={}\n",
    "    model_precision_scores[m] = {}\n",
    "    imp_dict[m] = {}\n",
    "    names_dict[m] = {}\n",
    "resultset=X_foursquare_beforedrops.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = {}\n",
    "X_test = {}\n",
    "y_train = {}\n",
    "y_test = {}\n",
    "for m in models:\n",
    "\n",
    "    X_train[m], X_test[m], y_train[m], y_test[m] = train_test_split(dictx[m], y, test_size = 0.3, random_state = 1)    \n",
    "    #x >> dictx[m][0]\n",
    "    # y =>> dictx[m][1]\n",
    "    print(X_train[m].shape, X_test[m].shape, y_train[m].shape, y_test[m].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model\n",
    "def f_importances_neg(coef, names,m):\n",
    "    \n",
    "    imp = coef\n",
    "    print((imp.shape))\n",
    "    imp,names = zip(*sorted(zip(list(imp)[0],names)))\n",
    "    imp = imp[:20]\n",
    "    names = names[:20]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title('Negative Weights of Logistic Classifier for Model \\''+m+'\\'', size = 10)\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)  \n",
    "    plt.xticks(size = 8)\n",
    "    plt.show()\n",
    "def f_importances_pos(coef, names,m):\n",
    "    imp = coef\n",
    "    print((imp.shape))\n",
    "    imp,names = zip(*sorted(zip(list(imp)[0],names)))\n",
    "    imp = imp[-20:]\n",
    "    names = names[-20:]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title('Positive Weights of Logistic Classifier for Model \\''+m+'\\'', size = 10)\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "#     plt.xlabel(size=8)\n",
    "    plt.xticks(size = 8)\n",
    "    plt.show()\n",
    "def f_importances_unimp(coef, names,m):\n",
    "    imp = coef\n",
    "    print((imp.shape))\n",
    "    imp,names = zip(*sorted(zip(list(imp)[0],names)))\n",
    "    lenimp_2 = len(imp)//2\n",
    "    imp = imp[lenimp_2-10:lenimp_2+10]\n",
    "    names = names[lenimp_2-10:lenimp_2+10]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title('Weights of Logistic Classifier for Model \\''+m+'\\'', size = 10)\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.xticks(size = 8)\n",
    "    plt.show()\n",
    "def f_importances_all(coef, names,m):\n",
    "    imp = coef\n",
    "    print((imp.shape))\n",
    "    imp,names = zip(*sorted(zip(list(imp)[0],names)))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title('Negative Weights of Logistic Classifier for Model \\''+m+'\\'', size = 10)\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.xticks(size = 8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Logistic Reeg\n",
    "imp = {}\n",
    "for m in models:\n",
    "#     dictx[m]\n",
    "#     model[m]\n",
    "# X_train[m], X_test[m], y_train[m], y_test[m]\n",
    "\n",
    "    logit_1 = LogisticRegression(C = 10000)\n",
    "#     print(X_train[m].shape,y_train[m].shape)\n",
    "    logit_1.fit(X_train[m], y_train[m])\n",
    "#     print(logit_1.score(X_test[m],y_test[m]))\n",
    "    model[m]['Logit'] = logit_1.score(X_test[m],y_test[m])\n",
    "#     resultset[m+'_Logit_predicttyp']=logit_1.predict(dictx[m])\n",
    "    y_pred = logit_1.predict(X_test[m])\n",
    "    y_true = y_test[m]\n",
    "    model_f1_scores[m]['Logit'] = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    model_recall_scores[m]['Logit'] = recall_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    model_precision_scores[m]['Logit'] = precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    f_importances_pos(logit_1.coef_, np.asarray(list(X_train['Raw'].columns)),m)\n",
    "    f_importances_neg(logit_1.coef_, np.asarray(list(X_train['Raw'].columns)),m)\n",
    "    f_importances_unimp(logit_1.coef_, np.asarray(list(X_train['Raw'].columns)),m)\n",
    "    imp3,names = zip(*sorted(zip(list(logit_1.coef_)[0],np.asarray(list(X_train['Raw'].columns)))))\n",
    "    names_dict[m]['Logit'] = names\n",
    "    imp_dict[m]['Logit'] =  imp3\n",
    "    f_importances_all(logit_1.coef_, np.asarray(list(X_train['Raw'].columns)),m)\n",
    "model_f1_scores\n",
    "pd.DataFrame(imp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureImportancePlot_dt(rf, labels,m):\n",
    "    importances = rf.feature_importances_[:]\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    #std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "    #         axis=0)\n",
    "    pl.figure(figsize=(5,5))\n",
    "    pl.title(\"Feature importances\")\n",
    "    pl.bar(range(indices.shape[0]), rf.feature_importances_[indices],\n",
    "       color=\"SteelBlue\", #yerr=std[indices]\n",
    "           align=\"center\")\n",
    "    pl.xticks(range(indices.shape[0]), np.array(labels)[indices], rotation=90)\n",
    "    pl.xlim([-1, indices.shape[0]])\n",
    "    pl.show()\n",
    "     \n",
    "    return rf.feature_importances_[indices], np.array(labels)[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = 5\n",
    "# print(y_train.shape, X_train.shape)\n",
    "for m in models:\n",
    "    #     dictx[m]\n",
    "    #     model[m]\n",
    "\n",
    "    OS = []\n",
    "#     param_grid = {'n_estimators':range(1,11),'max_depth':range(1,11),'max_leaf_nodes':range(2,11)}\n",
    "#     dt=DecisionTreeClassifier()\n",
    "#     gr=GridSearchCV(dt,param_grid=param_grid,scoring='roc_auc')\n",
    "#     ds=gr.fit(X_train[m],y_train[m])\n",
    "\n",
    "    for c in range(5):\n",
    "#         print (ds.best_params_,ds.best_params_['max_depth'],ds.best_params_['max_leaf_nodes'])\n",
    "        dt=DecisionTreeClassifier()\n",
    "        dt = DecisionTreeClassifier(max_depth=3)\n",
    "        dt.fit(X_train[m], y_train[m])\n",
    "        pred=dt.predict_proba(X_test[m])[:,1]\n",
    "        OS.append(dt.score(X_test[m],y_test[m]))\n",
    "    model[m]['DT'] = mean(OS)\n",
    "#     resultset[m+'_DT_predicttyp']=dt.predict(dictx[m])\n",
    "    y_pred = dt.predict(X_test[m])\n",
    "    y_true = y_test[m]\n",
    "    model_f1_scores[m]['DT'] = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    model_recall_scores[m]['DT'] = recall_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    model_precision_scores[m]['DT'] = precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    imp_dict[m]['DT'], names_dict[m]['DT'] =  featureImportancePlot_dt(dt, X_foursquare.columns,m)\n",
    "model_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f1_scores['Raw']['DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultset['actualtyp']=y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def featureImportancePlot(rf, labels,m):\n",
    "    '''plots feature importance for random forest\n",
    "    rf: the random forest model fit to the data\n",
    "    labels: the names of the features\n",
    "    '''\n",
    "    importances = rf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    importances_10 = rf.feature_importances_\n",
    "    indices_10 = np.argsort(importances_10)[::-1]\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "\n",
    "    pl.figure(figsize=(5,5))\n",
    "    pl.title(\"Feature importances of Random Forest for Model \"+m)\n",
    "    pl.bar(range(indices_10.shape[0]), rf.feature_importances_[indices_10],\n",
    "       color=\"SteelBlue\", yerr=std[indices_10], align=\"center\")\n",
    "    pl.xticks(range(indices.shape[0]), np.array(labels)[indices_10], rotation=90)\n",
    "    pl.xlim([-1, indices.shape[0]])\n",
    "    pl.show()\n",
    "    return rf.feature_importances_[indices], np.array(labels)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    #     dictx[m]\n",
    "    print(m)\n",
    "    param_grid = {'max_depth':range(1,11),'n_estimators':range(1,11),'max_leaf_nodes':range(2,11)}\n",
    "    rf=RandomForestClassifier()\n",
    "    gr=GridSearchCV(rf,param_grid=param_grid,scoring='roc_auc')\n",
    "    rs=gr.fit(X_train[m],y_train[m])\n",
    "    OS = []\n",
    "    for c in range(5):\n",
    "        print(rs.best_params_,rs.best_params_['max_depth'],rs.best_params_['max_leaf_nodes'])\n",
    "        rf = RandomForestClassifier(max_depth=rs.best_params_['max_depth'],max_leaf_nodes=rs.best_params_['max_leaf_nodes'])\n",
    "        rf.fit(X_train[m], y_train[m])\n",
    "        pred=rf.predict_proba(X_test[m])[:,1]\n",
    "        OS.append(rf.score(X_test[m],y_test[m]))\n",
    "    model[m]['RF'] = mean(OS)\n",
    "    resultset[m+'_RF_predicttyp']=rf.predict(dictx[m])\n",
    "    y_pred = rf.predict(X_test[m])\n",
    "    y_true = y_test[m]\n",
    "    model_f1_scores[m]['RF'] = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    model_recall_scores[m]['RF'] = recall_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    model_precision_scores[m]['RF'] = precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    imp_dict[m]['RF'], names_dict[m]['RF'] =  featureImportancePlot_dt(dt, X_foursquare.columns,m)\n",
    "model_f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the features have changed considerably with the updated binary typology-- users and checkins were the most important features initially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model\n",
    "def f_importances_neg(coef, names,m):\n",
    "    \n",
    "    imp = coef\n",
    "    print((imp.shape))\n",
    "    imp,names = zip(*sorted(zip(list(imp)[0],names)))\n",
    "    imp = imp[:20]\n",
    "    names = names[:20]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title('Negative Weights of SVM Classifier for Model \\''+m+'\\'', size = 10)\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)  \n",
    "    plt.xticks(size = 8)\n",
    "    plt.show()\n",
    "def f_importances_pos(coef, names,m):\n",
    "    imp = coef\n",
    "    print((imp.shape))\n",
    "    imp,names = zip(*sorted(zip(list(imp)[0],names)))\n",
    "    imp = imp[-20:]\n",
    "    names = names[-20:]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title('Positive Weights of SVM Classifier for Model \\''+m+'\\'', size = 10)\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "#     plt.xlabel(size=8)\n",
    "    plt.xticks(size = 8)\n",
    "    plt.show()\n",
    "def f_importances_unimp(coef, names,m):\n",
    "    imp = coef\n",
    "    print((imp.shape))\n",
    "    imp,names = zip(*sorted(zip(list(imp)[0],names)))\n",
    "    lenimp_2 = len(imp)//2\n",
    "    imp = imp[lenimp_2-10:lenimp_2+10]\n",
    "    names = names[lenimp_2-10:lenimp_2+10]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title('Weights of SVM Classifier for Model \\''+m+'\\'', size = 10)\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.xticks(size = 8)\n",
    "    plt.show()\n",
    "def f_importances_all(coef, names,m):\n",
    "    imp = coef\n",
    "    print((imp.shape))\n",
    "    imp,names = zip(*sorted(zip(list(imp)[0],names)))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title('Negative Weights of SVM Classifier for Model \\''+m+'\\'', size = 10)\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "#     plt.xlabel(size=8)\n",
    "    plt.xticks(size = 8)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# When C is very small, we are willing to tolerate more mistakes. If C is very big, this\n",
    "# means we hardly tolerate any mistakes. So, we cannot choose a very large C if our data is not\n",
    "# really separable. Let's however choose from a broad range of reasonable options.\n",
    "# param_grid = {'kernel':['linear'],'C':[np.exp(i) for i in np.linspace(-10,10,10)]}\n",
    "for m in models:\n",
    "    OS = []\n",
    "    #     dictx[m]\n",
    "        #     model[m]\n",
    "    rr = svm.SVC(gamma='auto')\n",
    "    rr.fit(X_train[m], y_train[m])\n",
    "    correct=1.0*(rr.predict(X_test[m])==np.asarray(y_test[m])).sum()/len(y_test[m])\n",
    "    print(correct)\n",
    "    print(rr.score(X_test[m],y_test[m]))\n",
    "    OS.append(correct)\n",
    "#     resultset[m+'_SVM_predicttyp']=rr.predict(dictx[m])\n",
    "    model[m]['SVM'] = mean(OS)\n",
    "    y_pred = rf.predict(X_test[m])\n",
    "    y_true = y_test[m]\n",
    "    model_f1_scores[m]['SVM'] = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    model_recall_scores[m]['SVM'] = recall_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    model_precision_scores[m]['SVM'] = precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    f_importances_pos(logit_1.coef_, np.asarray(list(X_train['Raw'].columns)),m)\n",
    "    f_importances_neg(logit_1.coef_, np.asarray(list(X_train['Raw'].columns)),m)\n",
    "    f_importances_unimp(logit_1.coef_, np.asarray(list(X_train['Raw'].columns)),m)\n",
    "    imp3,names = zip(*sorted(zip(list(logit_1.coef_)[0],np.asarray(list(X_train['Raw'].columns)))))\n",
    "    names_dict[m]['SVM'] = names\n",
    "    imp_dict[m]['SVM'] = imp3 \n",
    "model_f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_foursquare.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(model_f1_scores)\n",
    "df2 = pd.DataFrame(model_recall_scores)\n",
    "df3 =pd.DataFrame(model_precision_scores)\n",
    "result = pd.concat([df1, df2,df3], axis=1, sort=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./Results/Scores'+model_name+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_pd = pd.DataFrame()\n",
    "counter = {}\n",
    "for m in models:\n",
    "    print(m)\n",
    "    for standarized in modelslist:\n",
    "        for i, weights in enumerate(names_dict[m][standarized]):\n",
    "            standarized_m = str(standarized)+'_'+str(m)\n",
    "            names_pd.loc[standarized_m,weights] = imp_dict[m][standarized][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_pd.loc['DT_Raw'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_pd.to_csv('./Results/'+model_name+'.csv')\n",
    "names_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can refer to https://github.com/mv1742/updny_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)\n",
    "resultset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots below show the number of positive (gentrifying, 1) and negative (not-gentrifying, 0) typologies based on the actual typology labels and the predicted labels from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultset['actualtyp'].value_counts().plot(kind='bar', figsize=(5,2))\n",
    "resultset['actualtyp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    for i in modelslist:\n",
    "        resultset[m+'_'+i+'_predicttyp'].value_counts().plot(kind='bar',figsize=(5,2))\n",
    "        plt.show()\n",
    "        print(resultset[m+'_'+i+'_predicttyp'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all of the predicted results for the decision tree model are 0 (non-gentrifgying). The confusion matrix below shows [[TN, FP][FN, TP]]-- you can see that all of the results are negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(resultset.actualtyp, resultset.scaled_Logit_predicttyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_measure(resultset.actualtyp, resultset.scaled_Logit_predicttyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see that logit produces 30 positive results (19 true and 11 false), while random forest produces only 1 positive (it is true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_measure(resultset.actualtyp, resultset.scaled_RF_predicttyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_measure(resultset.actualtyp, resultset.o_SVM_predicttyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfull=data_sjoined_sum_merged.merge(resultset[[\"scaled_Logit_predicttyp\"]], right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_resulttyp(row):\n",
    "    if row[\"actualtyp\"] == 0:\n",
    "        if row[\"scaled_Logit_predicttyp\"] == 0:\n",
    "            return \"TN\"\n",
    "        elif row[\"scaled_Logit_predicttyp\"] == 1: \n",
    "            return \"FP\" \n",
    "    elif row[\"actualtyp\"] == 1:\n",
    "        if row[\"scaled_Logit_predicttyp\"] == 1:\n",
    "            return \"TP\"\n",
    "        elif  row[\"scaled_Logit_predicttyp\"] == 0:\n",
    "            return \"FN\"\n",
    "\n",
    "#df = df.assign(color=df.apply(set_color, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfinal=resultsfull.assign(scaled_Logit_restultyp=resultset.apply(set_resulttyp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16,16))\n",
    "resultsfinal.plot(column='scaled_Logit_restultyp', ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only positive results for the logit model (whether true or false positive) fell in the NYC and Jersey City areas-- no outer borough or other NJ/CT/NY tracts were picked up. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS",
   "language": "python",
   "name": "ads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
